{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b814e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import import_ipynb\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from autoencoder_classes import Encoder, Decoder, ConvAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "533704cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms for data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "data_dir = os.path.join(base_dir, 'split_dataset')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71b91b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose the best device to run on\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# new encoder object of the Encoder class defined; dame architecture for the saved weights\n",
    "encoder = Encoder(in_channels=3) \n",
    "\n",
    "# loads saved parameter dictionary from the file into encoder, \"map.location\" ensures tensors in the file are remapped to the chosen device\n",
    "encoder.load_state_dict(torch.load(\"encoder.pth\", map_location=device)) \n",
    "\n",
    "# moves encoder's parameters and buffers to the selected device\n",
    "encoder.to(device)\n",
    "\n",
    "#switches encoder to evaluation mode: turns off training-specific behaviors\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7926e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features\n",
    "train_features = []\n",
    "train_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, labels in train_loader:\n",
    "        data = data.to(device)\n",
    "        latent = encoder(data)\n",
    "        latent_flat = latent.view(latent.size(0), -1)\n",
    "        train_features.append(latent_flat.cpu())\n",
    "        train_labels.append(labels)\n",
    "\n",
    "train_features = torch.cat(train_features, dim=0).numpy()\n",
    "train_labels = torch.cat(train_labels, dim=0).numpy()\n",
    "\n",
    "# save extracted features\n",
    "np.save(\"train_features.npy\", train_features)\n",
    "np.save(\"train_labels.npy\", train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac63c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_studio_dir = os.path.join(data_dir, 'test_studio')\n",
    "\n",
    "test_studio_dataset = datasets.ImageFolder(root=test_studio_dir, transform=transform)\n",
    "test_studio_loader = DataLoader(test_studio_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5848927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for test sets\n",
    "test_studio_features = []\n",
    "test_studio_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_studio_loader:\n",
    "        data = data.to(device)\n",
    "        latent = encoder(data)\n",
    "        latent_flat = latent.view(latent.size(0), -1)\n",
    "        test_studio_features.append(latent_flat.cpu())\n",
    "        test_studio_labels.append(labels)\n",
    "\n",
    "test_studio_features = torch.cat(test_studio_features, dim=0).numpy()\n",
    "test_studio_labels = torch.cat(test_studio_labels, dim=0).numpy()\n",
    "\n",
    "np.save(\"test_studio_features.npy\", test_studio_features)\n",
    "np.save(\"test_studio_labels.npy\", test_studio_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e53108",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_realworld_dir = os.path.join(data_dir, 'test_realworld')\n",
    "\n",
    "test_realworld_dataset = datasets.ImageFolder(root=test_realworld_dir, transform=transform)\n",
    "test_realworld_loader = DataLoader(test_realworld_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b934c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for test sets\n",
    "test_realworld_features = []\n",
    "test_realworld_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_realworld_loader:\n",
    "        data = data.to(device)\n",
    "        latent = encoder(data)\n",
    "        latent_flat = latent.view(latent.size(0), -1)\n",
    "        test_realworld_features.append(latent_flat.cpu())\n",
    "        test_realworld_labels.append(labels)\n",
    "\n",
    "test_realworld_features = torch.cat(test_realworld_features, dim=0).numpy()\n",
    "test_realworld_labels = torch.cat(test_realworld_labels, dim=0).numpy()\n",
    "\n",
    "np.save(\"test_realworld_features.npy\", test_realworld_features)\n",
    "np.save(\"test_realworld_labels.npy\", test_realworld_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intelligent-systems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
