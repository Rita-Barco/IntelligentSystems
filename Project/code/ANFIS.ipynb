{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b242a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score,classification_report\n",
    "import skfuzzy as fuzz\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed53dedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = np.load(\"train_features.npy\")\n",
    "ytr = np.load(\"train_labels.npy\")\n",
    "num_classes = np.max(ytr) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8958f6",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Number of clusters \n",
    "n_clusters = 2\n",
    "m=2\n",
    "\n",
    "# Concatenate target for clustering\n",
    "Xexp=np.concatenate([Xtr, ytr.reshape(-1, 1)], axis=1)\n",
    "#Xexp=Xtr\n",
    "\n",
    "# Transpose data for skfuzzy (expects features x samples)\n",
    "Xexp_T = Xexp.T \n",
    "\n",
    "# Fuzzy C-means clustering\n",
    "centers, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
    "    Xexp_T, n_clusters, m=m, error=0.005, maxiter=1000, init=None,\n",
    ")\n",
    "\n",
    "centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd50bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sigma (spread) for each cluster\n",
    "sigmas = []\n",
    "for j in range(n_clusters):\n",
    "    # membership weights for cluster j, raised to m\n",
    "    u_j = u[j, :] ** m\n",
    "    # weighted variance for each feature\n",
    "    var_j = np.average((Xexp - centers[j])**2, axis=0, weights=u_j)\n",
    "    sigma_j = np.sqrt(var_j)\n",
    "    sigmas.append(sigma_j)\n",
    "sigmas=np.array(sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8b8ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard clustering from fuzzy membership\n",
    "cluster_labels = np.argmax(u, axis=0)\n",
    "print(\"Fuzzy partition coefficient (FPC):\", fpc)\n",
    "\n",
    "# Plot first two features with fuzzy membership\n",
    "plt.figure(figsize=(8,6))\n",
    "for j in range(n_clusters):\n",
    "    plt.scatter(\n",
    "        Xexp[cluster_labels == j, 0],             # Feature 1\n",
    "        Xexp[cluster_labels == j, 1],             # Feature 2\n",
    "        alpha=u[j, :],          # transparency ~ membership\n",
    "        label=f'Cluster {j}'\n",
    "    )\n",
    "\n",
    "plt.title(\"Fuzzy C-Means Clustering (with membership degree)\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cb7d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first two features with cluster assignments\n",
    "plt.figure(figsize=(8,6))\n",
    "for j in range(n_clusters):\n",
    "    plt.scatter(\n",
    "        Xexp[cluster_labels == j, 0],\n",
    "        Xexp[cluster_labels == j, 1],\n",
    "        label=f'Cluster {j}'\n",
    "    )\n",
    "\n",
    "plt.title(\"Fuzzy C-Means Clustering (CRISPEN)\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0003782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian formula\n",
    "def gaussian(x, mu, sigma):\n",
    "    return np.exp(-0.5 * ((x - mu)/sigma)**2)\n",
    "\n",
    "lin=np.linspace(-2, 4, 500)\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "y_aux=[]\n",
    "feature=0\n",
    "for j in range(n_clusters):\n",
    "# Compute curves\n",
    "    y_aux.append(gaussian(lin, centers[j,feature], sigmas[j,feature]))\n",
    "\n",
    "# Plot\n",
    "    plt.plot(lin, y_aux[j], label=f\"Gaussian μ={np.round(centers[j,feature],2)}, σ={np.round(sigmas[j,feature],2)}\")\n",
    "\n",
    "plt.title(\"Projection of the membership functions on Feature 2\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Degree of Membership\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdeec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Gaussian Membership Function\n",
    "# ---------------------------\n",
    "class GaussianMF(nn.Module):\n",
    "    def __init__(self, centers, sigmas, agg_prob):\n",
    "        super().__init__()\n",
    "        self.centers = nn.Parameter(torch.tensor(centers, dtype=torch.float32))\n",
    "        self.sigmas = nn.Parameter(torch.tensor(sigmas, dtype=torch.float32))\n",
    "        self.agg_prob=agg_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Expand for broadcasting\n",
    "        # x: (batch, 1, n_dims), centers: (1, n_rules, n_dims), sigmas: (1, n_rules, n_dims)\n",
    "        diff = abs((x.unsqueeze(1) - self.centers.unsqueeze(0))/self.sigmas.unsqueeze(0)) #(batch, n_rules, n_dims)\n",
    "\n",
    "        # Aggregation\n",
    "        if self.agg_prob:\n",
    "            dist = torch.norm(diff, dim=-1)  # (batch, n_rules) # probablistic intersection\n",
    "        else:\n",
    "            dist = torch.max(diff, dim=-1).values  # (batch, n_rules) # min intersection (min instersection of normal funtion is the same as the max on dist)\n",
    "        \n",
    "        return torch.exp(-0.5 * dist ** 2)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# TSK Model\n",
    "# ---------------------------\n",
    "class TSK(nn.Module):\n",
    "    def __init__(self, n_inputs, n_rules, centers, sigmas,agg_prob=False):\n",
    "        super().__init__()\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_rules = n_rules\n",
    "\n",
    "        # Antecedents (Gaussian MFs)\n",
    "        \n",
    "        self.mfs=GaussianMF(centers, sigmas,agg_prob) \n",
    "\n",
    "        # Consequents (linear functions of inputs)\n",
    "        # Each rule has coeffs for each input + bias\n",
    "        self.consequents = nn.Parameter(\n",
    "            torch.randn(n_inputs + 1,n_rules)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, n_inputs)\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Compute membership values for each input feature\n",
    "        # firing_strengths: (batch, n_rules)\n",
    "        firing_strengths = self.mfs(x)\n",
    "        \n",
    "        # Normalize memberships\n",
    "        # norm_fs: (batch, n_rules)\n",
    "        norm_fs = firing_strengths / (firing_strengths.sum(dim=1, keepdim=True) + 1e-9)\n",
    "\n",
    "        # Consequent output (linear model per rule)\n",
    "        x_aug = torch.cat([x, torch.ones(batch_size, 1)], dim=1)  # add bias\n",
    "\n",
    "        rule_outputs = torch.einsum(\"br,rk->bk\", x_aug, self.consequents)  # (batch, rules)\n",
    "        # Weighted sum\n",
    "        output = torch.sum(norm_fs * rule_outputs, dim=1, keepdim=True)\n",
    "\n",
    "        return output, norm_fs, rule_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32725ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Least Squares Solver for Consequents (TSK)\n",
    "# ---------------------------\n",
    "def train_ls(model, X, y):\n",
    "    with torch.no_grad():\n",
    "        _, norm_fs, _ = model(X)\n",
    "\n",
    "        # Design matrix for LS: combine normalized firing strengths with input\n",
    "        X_aug = torch.cat([X, torch.ones(X.shape[0], 1)], dim=1)\n",
    "        \n",
    "        Phi = torch.einsum(\"br,bi->bri\", X_aug, norm_fs).reshape(X.shape[0], -1)\n",
    "        \n",
    "        # Solve LS: consequents = (Phi^T Phi)^-1 Phi^T y\n",
    "        \n",
    "        theta= torch.linalg.lstsq(Phi, y).solution\n",
    "    \n",
    "        \n",
    "        model.consequents.data = theta.reshape(model.consequents.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86514752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Gradient Descent Training \n",
    "# ---------------------------\n",
    "def train_gd(model, X, y, epochs=100, lr=1e-3):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    for _ in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred, _, _ = model(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        # print(loss) commented so that the PDF file is not that large\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8443f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Hybrid Training (Classic ANFIS)\n",
    "# ---------------------------\n",
    "def train_hybrid_anfis(model, X, y, max_iters=10, gd_epochs=20, lr=1e-3):\n",
    "    train_ls(model, X, y)\n",
    "    for _ in range(max_iters):\n",
    "        # Step A: GD on antecedents (freeze consequents)\n",
    "        model.consequents.requires_grad = False\n",
    "        train_gd(model, X, y, epochs=gd_epochs, lr=lr)\n",
    "\n",
    "        # Step B: LS on consequents (freeze antecedents)\n",
    "        model.consequents.requires_grad = True\n",
    "        model.mfs.requires_grad = False\n",
    "        train_ls(model, X, y)\n",
    "\n",
    "        # Re-enable antecedents\n",
    "        model.mfs.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a7030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = TSK(n_inputs=Xtr.shape[1], n_rules=n_clusters, centers=centers[:,:-1], sigmas=sigmas[:,:-1])\n",
    "\n",
    "Xtr = torch.tensor(Xtr, dtype=torch.float32)\n",
    "ytr = torch.tensor(ytr, dtype=torch.float32)\n",
    "Xte = torch.tensor(Xte, dtype=torch.float32)\n",
    "yte = torch.tensor(yte, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d5782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with ANFIS:\n",
    "train_hybrid_anfis(model, Xtr, ytr.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b74421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, _, _=model(Xte)\n",
    "\n",
    "#performance metric for regression\n",
    "print(f'MSE:{mean_squared_error(yte.detach().numpy(),y_pred.detach().numpy())}') #regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intelligent-systems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
